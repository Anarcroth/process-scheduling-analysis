\documentclass{article}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{color}
\usepackage{fullpage}
\usepackage{pgfgantt}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{relsize}
\usepackage{epigraph}
\usepackage{parskip}

\renewcommand{\familydefault}{\sfdefault}

\definecolor{pr0}{RGB}{61, 255, 12}
\definecolor{pr1}{RGB}{208, 231, 11}
\definecolor{pr2}{RGB}{255, 190, 0}
\definecolor{pr3}{RGB}{231, 149, 11}
\definecolor{pr4}{RGB}{255, 95, 6}
\definecolor{pr5}{RGB}{231, 20, 3}
\definecolor{pr6}{RGB}{255, 12, 190}

\definecolor{codebg}{gray}{0.9}
\definecolor{codehl}{RGB}{82, 139, 255}
\newcommand{\code}[1]{\colorbox{codebg}{{\color{black}\texttt{#1}}}}

\title{Senior Project Thesis\\
  \large Process scheduling - comparison and contrast}
\date{\today}
\author{Martin Nestorov}
\linespread{1}

\begin{document}

\maketitle
\pagenumbering{arabic}

\newpage

\section{Introduction}

Every Operating System has some type of process handling capabilities, be that in the form of simple queue structure, or in some complex algorithm. This is also specific to the different types of systems that are handling the jobs. Some embedded systems do not have the capacity to handle complex operations, which forces them to have simple schedulers. One such example would be preemptive OS's, running on batch jobs.

There are several process scheduling algorithms that are used in batch, interactive, and real-time systems. These include, but are not limited to, First Come First Serve (\textbf{FCFS}), Shortest Job First (\textbf{SJF}), Priority Job First (\textbf{PJF}), \textbf{Round-Robin} Scheduling, Guaranteed Scheduling, Lottery Scheduling, \textbf{Multilevel Queue} Scheduling, etc. All of them have their advantages and weaknesses. Some are simpler and work for small systems, while others are more complex, but distribute the workload better. The purpose of this project is to analyze and compare these different algorithms, to show where they flourish and where they fall.

Another thing to consider is the type of the system that lies under the processes. In general, we can either consider a \textit{Real-time} system, or an \textit{Interactive} one. We are all together omitting \textit{Batch} systems, as they are no longer viable and interesting. \textit{Real-time} systems are such that take into consideration time as an essential goal. Typically, one or more devices can stimulate the system and it has to react accordingly in a certain amount of time. \textit{Interactive} systems, much like the 'Real-time' ones, can and are stimulated by other programs, but don't have such a strict time constraints.

I personally find the topic of these intricate systems fascinating. All of these schedulers have something to teach us about optimization and managing complex systems. Being able to control an entire Operating Systems is no joke, so a good handle on \textit{Process Scheduling Algorithms} is vital for any Computer Scientist. As I aspire to one day write kernel code, this project closely relates to my interests and is a good preparation for any further advancements in the fields of \textit{System programming}. Although this project is big in size and complexity, the desire to learn proves to justify any means to achieve the goal.

\epigraph{He who has a why to live can bear almost any how}{\textit{Friedrich Nietzsche}}

The application is created by using \code{C++} and the \code{ncurses} library. The reason to pick \textit{C++} is due to its high granularity and fine tuning capabilities. With C++, I can control every aspect of the program with high accuracy, which is needed for scheduling algorithms. The \textit{ncurses} library provides a nice platform for building \textit{terminal-based} applications. It allows for easy interaction with terminals, controlling text output, color output, \textit{IO} operations, etc. It also provides a clean and pretty \textit{user-interface}, which is always a welcome benefit, especially if the work is done in C++. The \textit{UI} will have several panels, indicating the different algorithms and processes that can be selected, and also what are the contents of the different \code{queues}. There would be information for each algorithm and statistical summaries after each round of execution. The UI aims at being both easy to use, but at the same time, be clear and helping people evaluate the different algorithms.

As a final goal, this project is to be shared and extended with anyone who is interested in learning the mechanics of process scheduling. It can be used as a learning and pedagogical tool. Future plans hold that the project be tailored for introductory courses on Operating Systems, where students will have a first hand experience of seeing how these algorithms work and what kind of outputs they produce.

\section{Specification and Analysis of the Software Requirements}

\section{Design of the Software solution}

This software uses several algorithms and data-structures that play a key role in the whole inner-workings. Because the purpose of the project is to show how different algorithms affect the process execution of \textit{Real-Time} systems, we have to talk about each used algorithm and the accompanying data-structures.

But before we do that, we have to cover several structural decisions that have been made in order for the algorithm explanations to make sense.

Usually, in scheduling algorithms we have \code{PCB} blocks which hold references to the actual process, and through those blocks, we make decisions on which process should be executed next. Instead of doing this, because it adds another layer of complexity, not needed in this case, the role of a process and a PCB block is substituted with just a \code{process} class. It holds both the metadata found in PCBs and has the workings of processes. Thus, when in the text a reference is made to a process, a mental note should be made that it has a duality in it, for it holds two structures. The explanation of the \code{process} structure, as well as the other classes, can be found further down.

Another aspect that should be considered is that this project tries to imitate a \textit{Real-Time} system. This means that the scheduler has the notion of preemptive tasks and of \textit{IO} operations. Some of algorithms used are non-primitive and have been used in old \textit{batch systems} and \textit{interactive systems}. Thus, these algorithms have been tailored in order to work with a modern approach of building schedulers. When we refer to preemptive systems, it is meant that the OS decides when a process should be forced into a context-switch and when it should be taken from the \code{ready\_queue}. Also, Real Time systems do not wait for IO to end, thus they switch to the next ready process. For instance, the \textbf{FCFS} algorithm originally was used in non-preemptive batch systems, but in this project, each process is preempted upon requesting IO operations. Then, while waiting for that process to finish with IO, the next ready one is taken from the queue.

Having these distinctions made, we can then proceed to the algorithms and data-structures used.

\subsection{Algorithms and Data-structures}

\subsubsection{FCFS}

The \textbf{F}irst \textbf{C}ome \textbf{F}irst \textbf{S}erve algorithm is one of the easiest to understand and implement. It can be looked at from many different angles. \textbf{FCFS} can be seen as a \code{linked-list} or a \code{queue}, which just serves each incoming process to the CPU for execution. When a new process is created, it is put at the back of the \code{ready\_queue}. Then each process, one by one, is taken from the head of the queue and is given to the CPU for execution. It really depends on what type of system is running this scheduler, but in general, this algorithm, although easy, is not the most effective one to have. Because each process can take any time to finish, it can stall the whole system with its execution. For instance, if we were to have several processes and one is to be long in execution time, depending on their time of arrival, we can either quickly go through all of them, or we can wait for a long time.

In this project, the \textbf{FCFS} algorithm is created using a \code{vector} to hold all of the processes in sequential manner. At the start of the algorithm, we just take each next process for execution, wait for its time to live (\code{ttl}) and then we proceed to the next one in line. Because this project tries to imitate a \textit{Real-Time} system, we also check if each process will do an \textit{IO} operation. If so, the process is then sent to an \code{exec\_io} routine, and the next process is then taken. This means that the \code{done\_queue} will not be populated in the exact same order as the processes have been created in the \code{ready\_queue}, because of these \textit{IO} operations. Regardless, this still follows the \textbf{FCFS} pattern, and we can see that indeed, each process is taken from the head of the queue (technically vector).

\

\textbf{Evaluation}

\

\textbf{FCFS} gives us a few benefits. First, it is very simple to implement and understand. From this standpoint, it's a great algorithm for small batch systems. But on the other hand, it doesn't scale well. It can stall if there is \textbf{no} preemption and a \textbf{convoy effect} might occur, which means that all other processes wait for the currently running one to finish. To summarize:

\begin{table}[h!]
  \begin{tabularx}{\linewidth}{>{\parskip1ex}X@{\kern4\tabcolsep}>{\parskip1ex}X}
    \toprule
    \hfil\bfseries Pros & \hfil\bfseries Cons \\
    \cmidrule(r{3\tabcolsep}){1-1}\cmidrule(l{-\tabcolsep}){2-2}

    Easy to implement\par
    Easy to understand\par
    Works good for simple systems and batch systems\par

    &

    Can be slow\par
    Doesn't scale\par
    High risk of convoy effect\par
    System can stall if not preemptive\par
    Bad prediction for \textit{Waiting time} and \textit{Turnaround time} \\
    \bottomrule
  \end{tabularx}
  \caption{Pros and Cons of FCFS}
\end{table}

\

\textit{Example}

Let's take a set of processes and see how they would hold under this algorithm. We generate 5 random processes.

\begin{table}[h!]
  \begin{center}
    \label{tab:FCFS processes}
    \begin{tabular}{c|c}
      \toprule
      \textbf{Process ID} & \textbf{Time To Live} \\
      \midrule
      c37f & 2 \\
      e2fc & 5 \\
      792d & 3 \\
      0a35 & 5 \\
      3207 & 5 \\
      \bottomrule
    \end{tabular}
    \caption{FCFS processes table}
  \end{center}
\end{table}

From this, we can create the following \textbf{Gantt chart}.

\

\begin{ganttchart}[
  expand chart=\textwidth,
  hgrid={black}
  ]{1}{20}
  \gantttitle{FCFS}{20} \\
  \gantttitlelist{1,...,20}{1} \\
  \ganttbar[bar/.append style={fill=pr2}]{c37f}{1}{2} \\
  \ganttbar[bar/.append style={fill=pr3}]{e2fc}{3}{7} \\
  \ganttbar[bar/.append style={fill=pr2}]{792d}{8}{10} \\
  \ganttbar[bar/.append style={fill=pr3}]{0a35}{11}{15} \\
  \ganttbar[bar/.append style={fill=pr3}]{3207}{16}{20} \\
\end{ganttchart}

Then we can calculate the average \textbf{Waiting time} and \textbf{Turnaround time}.

\begin{table}[h!]
  \begin{center}
    \label{tab:FCFS times}
    \begin{tabular}{c|c|c}
      \toprule
      \textbf{Process ID} & \textbf{Waiting time} & \textbf{Turnaround time} \\
      \midrule
      c37f & 0 & 2 \\
      e2fc & 2 & 5 \\
      792d & 7 & 3 \\
      0a35 & 10 & 5 \\
      3207 & 15 & 5 \\
      \bottomrule
      \toprule
      \textbf{Average} & \textbf{6.8} & \textbf{4} \\
    \end{tabular}
    \caption{FCFS times table}
  \end{center}
\end{table}

Of course this is a fairly simple example, because the processes do not take as long to execute, and we are also not taking into consideration the fact that these processes \textit{might} have some IO to do.

\subsubsection{SJF}

The \textbf{S}hortest \textbf{J}ob \textbf{F}irst is another easy to understand, not so easy to implement algorithm. The SJF is an optimal algorithm, because it takes the greedy approach. It tries to finish all of the shortest processes first, which would cause the whole set of processes to finish as quick as possible. But there is a downside to this. This algorithm is not practically applicable, because it either relies on information beforehand for each process, or it has to do estimations for each upcoming process. Usually there is no way to know for how long a process will execute. In general, depending on what information we have, there are two ways to approach this algorithm.

\textbf{Note:} much like the FCFS, we also take into account the fact that we might have IO operations and we also preempt every process that does such actions.

\

\textbullet \ Method 1

In a perfect world, we would be graced with the knowledge of how long each job would. Thus, one way is to look in the \code{ready\_queue} and arrange the processes by their execution time in increasing manner (from smallest to largest). The shortest job will run first, then the second shortest one, and so on. Because each job has a \textit{pre-defined} execution time, which we take as a \textit{given}, based on that value, we sort the queue. This is the simpler approach because it only relies on information that is already given to us. It is important to note that this algorithm is a special case for a \textbf{PFJ} (Priority First Job) algorithm, because we are organizing the processes based on their execution time, which would be a form of a priority measurement.

\

\textbullet \ Method 2

Continuing from \textit{Method 1}, we do not live in a perfect world and as we mentioned earlier, because we do not know before-hand what is the \textit{actual} time of execution for each process, we try to \textit{guess it}. This is done by predicting the next job execution time on the basis of the previous jobs. This so called \textit{exponential average} of the measured lengths of the previous jobs will provide a good guess as to what to expect. The \textit{exponential average} can be defined as follows: Let \scalebox{1.1}{\(t_{n}\)} be the length of the nth CPU burst. Let \scalebox{1.1}{\(\tau_{n+1}\)} be our prediction for the next CPU burst. Then \scalebox{1.1}{\(\forall \alpha,  0 \leq \alpha \leq 1\)}, we define

\

\begin{equation}
  \mathlarger{\tau_{n+1} = \alpha t_{n} + (1 - \alpha)\tau_{n}}
\end{equation}

\

Where \scalebox{1.1}{\(t_{n}\)} is the most recent information we have, \scalebox{1.1}{\(\tau_{n}\)} is the previous prediction, and \scalebox{1.1}{\(\alpha\)} is the weight of our past predictions. If \scalebox{1.1}{\(\alpha = 0 \rightarrow \tau_{n+1} = \tau_{n}\)}, which means that the previous history does not matter. If \scalebox{1.1}{\(\alpha = 1 \rightarrow \tau_{n+1} = t_{n}\)}, which means that only the most recent history matters. A good middle value (quite literally) can be to put \scalebox{1.1}{\(\alpha = {{}^{1}\!/_{2}}\)}. This way, both recent and past history have equal weight on the next \textit{exponential average}.

The expanded \textit{exponential average} formula looks like this

\

\begin{equation}
  \mathlarger{\tau_{n+1} = \alpha t_{n} + (1 - \alpha)\alpha t_{n - 1} + \dots + (1 - \alpha)^{j} \alpha t_{n - j} + \dots + (1 - \alpha)^{n + 1} \tau_{0}}
\end{equation}

\

Usually, \scalebox{1.1}{\(\alpha\)} is less than 1, thus each successive term has less and less weight than the previous one. By using this formula, we can then make an informed decision on how to execute each incoming process.

One thing that arises in this algorithm is why we must make a guess as to which process should be executed? Why is this happening? This type of guessing is done only here, while anywhere else, we do not need to make presumptions. The reason is that for all other algorithms, we either have a constant \code{TIME\_QUANTUM}, which is used to define each CPU burst (used in \textbf{Round-Robin Scheduling}), or we wait for the process to tell us if it's done or not (such as the case with \textbf{FCFS}). Here, however, we have to \textit{dynamically} specify the CPU burst time on each new process execution. This forces us to keep track of each execution time.

\

\textbf{Evaluation}

\

\begin{table}[h!]
  \begin{tabularx}{\linewidth}{>{\parskip1ex}X@{\kern4\tabcolsep}>{\parskip1ex}X}
    \toprule
    \hfil\bfseries Pros & \hfil\bfseries Cons \\
    \cmidrule(r{3\tabcolsep}){1-1}\cmidrule(l{-\tabcolsep}){2-2}

    Optimal\par
    A good academic exercise\par
    Can produce fast results\par

    &

    Somewhat difficult to implement\par
    Cannot be used in a real system\par
    Still might have a process that stalls \\
    \bottomrule
  \end{tabularx}
  \caption{Pros and Cons of FCFS}
\end{table}

In this case we might think that FCFS is the better algorithm, since at least it has some real life value to it, but that's not the immediate case. Although we are dealing with a hypothetical algorithm here, it is still worth it to check what are the times for SJF. If we run an example, we would see that SJF has better waiting time for each process, where the turnaround time doesn't change. Thus, SJF yields better results on average that FCFS.

\

\textit{Example}

Let's take again a set of processes and see how they would work. Then we can create the \textbf{Gantt chart}.

\begin{table}[h!]
  \begin{center}
    \label{tab:SJF processes}
    \begin{tabular}{c|c}
      \toprule
      \textbf{Process ID} & \textbf{Time To Live} \\
      \midrule
      9479 & 2 \\
      7470 & 3 \\
      2b62 & 4 \\
      047c & 4 \\
      d19c & 7 \\
      \bottomrule
    \end{tabular}
    \caption{SJF processes table}
  \end{center}
\end{table}

\

\begin{ganttchart}[
  expand chart=\textwidth,
  hgrid={black}
  ]{1}{20}
  \gantttitle{SJF}{20} \\
  \gantttitlelist{1,...,20}{1} \\
  \ganttbar[bar/.append style={fill=pr1}]{9479}{1}{2} \\
  \ganttbar[bar/.append style={fill=pr3}]{7470}{3}{5} \\
  \ganttbar[bar/.append style={fill=pr3}]{2b62}{6}{9} \\
  \ganttbar[bar/.append style={fill=pr3}]{047c}{10}{13} \\
  \ganttbar[bar/.append style={fill=pr4}]{d19c}{14}{20} \\
\end{ganttchart}

\

Then we can calculate the average \textbf{Waiting time} and \textbf{Turnaround time}.

\begin{table}[h!]
  \begin{center}
    \label{tab:SJF times}
    \begin{tabular}{c|c|c}
      \toprule
      \textbf{Process ID} & \textbf{Waiting time} & \textbf{Turnaround time} \\
      \midrule
      9479 & 0 & 2 \\
      7470 & 2 & 3 \\
      2b62 & 5 & 4 \\
      047c & 9 & 4 \\
      d19c & 13 & 7 \\
      \bottomrule
      \toprule
      \textbf{Average} & \textbf{5.8} & \textbf{4} \\
    \end{tabular}
    \caption{SJF times table}
  \end{center}
\end{table}

\subsubsection{Round-Robin}



\section{Implementation}

This software is developed entirely with the \code{C++} programming language. All of the implementation uses the \code{C++ 11} standard (and up). The \code{C++ 11} standard and all of its follow-up additions, all the way up to \code{C++ 20}, have great benefits to creating modern, safe, and easy to manage software. Many functionalities introduced since \code{C++ 11} have been used to create this project. Most noticeably, the use of lambda functions, collection manipulators, threads and mutexes, and many more, play a key role.

In addition to this, the famous library \code{ncurses} is used in order to make working with terminal emulators easier. \code{ncurses} provides an \code{API} for manipulating the graphics and output of the terminal. Since this is an application, based on working with a terminal emulator, such a library would be of great help. The specific terminal that was used to test and run the application is \code{xterm}, but this was also tested on \code{gnome-terminal}.

The operating system used to create the software is \code{Arch Linux}, with additional testing environment under \code{Fedora 29}.

\section{Testing}

\section{Result and Conclusion}

\section{References}

\end{document}